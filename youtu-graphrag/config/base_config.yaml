construction:
  chunk_size: 1000
  datasets_no_chunk:
    - hotpot
    - 2wiki
    - musique
    - graphrag-bench
    - annoy_chs
    - annoy_eng
    - demo
  max_workers: 32
  mode: agent
  overlap: 200
  tree_comm:
    #    embedding_model: all-MiniLM-L6-v2
    embedding_model: BAAI/bge-m3
    enable_fast_mode: true
    struct_weight: 0.3

datasets:
  hotpot:
    corpus_path: data/hotpotqa/hotpotqa_corpus.json
    qa_path: data/hotpotqa/hotpotqa.json
    schema_path: schemas/hotpot.json
    graph_output: output/graphs/hotpot_new.json
  2wiki:
    corpus_path: data/2wiki/2wikimultihopqa_corpus.json
    qa_path: data/2wiki/2wikimultihopqa.json
    schema_path: schemas/2wiki.json
    graph_output: output/graphs/2wiki_new.json
  musique:
    corpus_path: data/musique/musique_corpus.json
    qa_path: data/musique/musique.json
    schema_path: schemas/musique.json
    graph_output: output/graphs/musique_new.json
  graphrag-bench:
    corpus_path: data/graphrag-bench-reformat/bench_corpus.json
    qa_path: data/graphrag-bench-reformat/graphrag-bench.json
    schema_path: schemas/graphrag-bench.json
    graph_output: output/graphs/graphrag-bench_new.json
  demo:
    corpus_path: data/demo/demo_corpus.json
    qa_path: data/demo/demo.json
    schema_path: schemas/demo.json
    graph_output: output/graphs/demo_new.json
  demo1:
    schema_path: schemas/demo1.json
  anony_chs:
    corpus_path: data/anony_chs/final_chunk_corpus.json
    qa_path: data/anony_chs/final_qa_pairs.json
    schema_path: schemas/anony_chs.json
    graph_output: output/graphs/anony_chs_new.json
  anony_eng:
    corpus_path: data/anony_eng/final_chunk_corpus.json
    qa_path: data/anony_eng/final_qa_pairs.json
    schema_path: schemas/anony_eng.json
    graph_output: output/graphs/anony_eng_new.json
  aviation:
    schema_path: schemas/aviation.json
    prompt_type: aviation

#embeddings:
#  batch_size: 32
#  device: cuda
#  max_length: 512
#  model_name: all-MiniLM-L6-v2

#显存不够记得改
embeddings:
  batch_size: 32
  device: cuda:4
  max_length: 1024
  model_name: BAAI/bge-m3

output:
  base_dir: output
  chunks_dir: output/chunks
  graphs_dir: output/graphs
  logs_dir: output/logs
  save_chunk_details: true
  save_intermediate_results: true
performance:
  batch_size: 16
  max_workers: 32
  memory_optimization: true
  parallel_processing: true
prompts:
  construction:
    general: "你是一位专家级的信息提取和结构化数据组织者。你的任务是分析提供的文本，并以结构化的JSON格式提取尽可能多的有价值实体、属性及它们之间的关系。

    指南：
    1. 优先基于以下预定义Schema进行提取：
       ```{schema}```
    2. 灵活性：如果上下文中包含Schema未涵盖但有价值的知识，也请按需提取；
    3. 简洁性：你提取的属性（Attributes）和三元组（Triples）应互为补充，避免语义冗余；
    4. 全面性：不要遗漏上下文中的任何有用信息；
    5. 输出格式：仅返回如下 **示例输出** 所示的JSON格式：
       - Attributes: 将每个实体映射到其描述性特征列表。
       - Triples: 以 `[实体1, 关系, 实体2]` 的格式列出实体间的关系。
       - Entity_types: 根据提供的Schema将每个实体映射到其类型。

    文本内容：
    ```{chunk}```

    示例输出：
    {{
      \"attributes\": {{
        \"李白\": [\"职业: 诗人\", \"朝代: 唐朝\"]
      }},
      \"triples\": [
        [\"李白\", \"创作\", \"静夜思\"],
        [\"静夜思\", \"体裁\", \"五言绝句\"]
      ],
      \"entity_types\": {{
        \"李白\": \"person\",
        \"静夜思\": \"creative_work\",
        \"五言绝句\": \"genre\"
      }}
    }}"
    general_incremental: "你是一位专家级的信息提取和结构化数据组织者。你的任务是分析提供的文本，并以结构化的JSON格式提取尽可能多的有价值实体、属性及它们之间的关系。

    【参考知识库】：
    以下是图谱中已存在的、与当前文本最相关的知识结构，请参考其术语规范和逻辑，保持提取的一致性：
    ```{examples}```
    
    指南：
    1. 优先基于以下预定义Schema进行提取：
       ```{schema}```
    2. 灵活性：如果上下文中包含Schema未涵盖但有价值的知识，也请按需提取；
    3. 简洁性：你提取的属性（Attributes）和三元组（Triples）应互为补充，避免语义冗余；
    4. 全面性：不要遗漏上下文中的任何有用信息；
    5. 输出格式：仅返回如下 **示例输出** 所示的JSON格式：
       - Attributes: 将每个实体映射到其描述性特征列表。
       - Triples: 以 `[实体1, 关系, 实体2]` 的格式列出实体间的关系。
       - Entity_types: 根据提供的Schema将每个实体映射到其类型。

    文本内容：
    ```{chunk}```

    示例输出：
    {{
      \"attributes\": {{
        \"李白\": [\"职业: 诗人\", \"朝代: 唐朝\"]
      }},
      \"triples\": [
        [\"李白\", \"创作\", \"静夜思\"],
        [\"静夜思\", \"体裁\", \"五言绝句\"]
      ],
      \"entity_types\": {{
        \"李白\": \"person\",
        \"静夜思\": \"creative_work\",
        \"五言绝句\": \"genre\"
      }}
    }}"
    aviation: "你是一位航空发动机维修专家和知识图谱构建助手。你的核心任务是从维修手册或故障日志中，精准提取故障诊断逻辑，构建结构化的知识图谱。

    指南：
    1. **严格遵循Schema**：优先提取以下类型的实体和关系（如果文本中存在）：
       - 实体类型：[故障现象, 故障原因, 解决方案, 部件, 系统, 参数指标, 工具设备]
       - 关系类型：[起因于, 解决措施为, 发生于, 属于系统, 导致, 涉及参数]
       ```{schema}```
    2. **捕捉因果链**：特别关注“现象 -> 原因 -> 措施”的逻辑链条。如果文中提到“由于...导致...”或“如果...则...”，必须提取为关系。
    3. **专业术语保留**：实体名称必须严格保持原文中的专业术语（如'HP-30 K II'、'N2转速'），严禁进行翻译或模糊化概括。
    4. **属性提取**：将具体的数值限制（如'56±4秒'）、状态描述（如'卡滞'、'断裂'）提取为实体的属性。
    5. 输出格式：仅返回如下 **示例输出** 所示的JSON格式：
       - Attributes: 将每个实体映射到其描述性特征列表。
       - Triples: 以 `[实体1, 关系, 实体2]` 的格式列出实体间的关系。
       - Entity_types: 根据提供的Schema将每个实体映射到其类型。

    文本内容：
    ```{chunk}```

    示例输出：
    {{
      \"attributes\": {{
        \"起动转速悬挂\": [\"状态: 转速停滞\", \"严重程度: 高\"],
        \"燃油压力低\": [\"数值: 低于0.4MPa\"],
        \"HP-30 K II\": [\"型号: 30K II\", \"类型: 燃油泵\"]
      }},
      \"triples\": [
        [\"起动转速悬挂\", \"起因于\", \"燃油压力低\"],
        [\"燃油压力低\", \"发生于\", \"HP-30 K II\"],
        [\"燃油压力低\", \"解决措施为\", \"更换燃油泵\"]
      ],
      \"entity_types\": {{
        \"起动转速悬挂\": \"故障现象\",
        \"燃油压力低\": \"故障原因\",
        \"HP-30 K II\": \"部件\",
        \"更换燃油泵\": \"解决方案\"
      }}
    }}"
    aviation_incremental: "你是一位航空发动机维修专家和知识图谱构建助手。你的核心任务是从维修手册或故障日志中，精准提取故障诊断逻辑，构建结构化的知识图谱。

    【参考知识库】：
    以下是图谱中已存在的、与当前文本最相关的知识结构，请参考其术语规范和逻辑，保持提取的一致性：
    ```{examples}```

    指南：
    1. **严格遵循Schema**：优先提取以下类型的实体和关系（如果文本中存在）：
       - 实体类型：[故障现象, 故障原因, 解决方案, 部件, 系统, 参数指标, 工具设备]
       - 关系类型：[起因于, 解决措施为, 发生于, 属于系统, 导致, 涉及参数]
       ```{schema}```
    2. **捕捉因果链**：特别关注“现象 -> 原因 -> 措施”的逻辑链条。如果文中提到“由于...导致...”或“如果...则...”，必须提取为关系。
    3. **专业术语保留**：实体名称必须严格保持原文中的专业术语（如'HP-30 K II'、'N2转速'），严禁进行翻译或模糊化概括。
    4. **属性提取**：将具体的数值限制（如'56±4秒'）、状态描述（如'卡滞'、'断裂'）提取为实体的属性。
    5. 输出格式：仅返回如下 **示例输出** 所示的JSON格式：
       - Attributes: 将每个实体映射到其描述性特征列表。
       - Triples: 以 `[实体1, 关系, 实体2]` 的格式列出实体间的关系。
       - Entity_types: 根据提供的Schema将每个实体映射到其类型。

    文本内容：
    ```{chunk}```

    示例输出：
    {{
      \"attributes\": {{
        \"起动转速悬挂\": [\"状态: 转速停滞\", \"严重程度: 高\"],
        \"燃油压力低\": [\"数值: 低于0.4MPa\"],
        \"HP-30 K II\": [\"型号: 30K II\", \"类型: 燃油泵\"]
      }},
      \"triples\": [
        [\"起动转速悬挂\", \"起因于\", \"燃油压力低\"],
        [\"燃油压力低\", \"发生于\", \"HP-30 K II\"],
        [\"燃油压力低\", \"解决措施为\", \"更换燃油泵\"]
      ],
      \"entity_types\": {{
        \"起动转速悬挂\": \"故障现象\",
        \"燃油压力低\": \"故障原因\",
        \"HP-30 K II\": \"部件\",
        \"更换燃油泵\": \"解决方案\"
      }}
    }}"
    general_eng: "You are an expert information extractor and structured data organizer.\
      \ Your task is to analyze the provided text and extract as many valuable entities,\
      \ their attributes, and relations as possible in a structured JSON format. \
      \ \n\nGuidelines:\n1. Prioritize the following predefined schema for extraction;\n\
      \   ```{schema}```\n2. Flexibility: If the context doesn't fit the predefined\
      \ schema, extract the valuable knowledge as needed;\n3. Conciseness: The Attributes\
      \ and Triples you extract should be complementary and no semantic redundancy.\n\
      4. Do NOT miss any useful information in the context;\n5. Output Format: Return\
      \ only JSON as **Example Output** with:  \n   - Attributes: Map each entity\
      \ to its descriptive features.  \n   - Triples: List relations between entities\
      \ in `[entity_mention1, relation, entity_mention2]` format.\n   - Entity_types:\
      \ Map each entity to its schema type based on the provided schema.\n\n```{chunk}```\n\
      \nExample Output:  \n{{\n  \"attributes\": {{\n    \"Stephen King\": [\"profession:\
      \ author\"]\n  }},\n  \"triples\": [\n    [\"Shawshank Redemption\", \"based\
      \ on\", \"Rita Hayworth and Shawshank Redemption\"],\n    [\"Shawshank Redemption\"\
      , \"directed by\", \"Frank Darabont\"]\n  ],\n  \"entity_types\": {{\n    \"\
      Stephen King\": \"person\",\n    \"Shawshank Redemption\": \"creative_work\"\
      ,\n    \"Rita Hayworth and Shawshank Redemption\": \"creative_work\",\n    \"\
      Frank Darabont\": \"person\"\n  }}\n}}\n"
    novel: "你是小说信息提取专家，请根据小说内容，参考以下schema，提取小说中的主要人物、人物关系、人物属性、人物事件等关键信息，并严格按照示例返回一个JSON格式。\n\
      \n小说内容:\n```{chunk}```\n\n参考schema:\n```{schema}```\n\n要求：\n1. 主要人物：包括主角、配角、反派等。\n\
      2. 人物关系：包括人物之间的互动、关系等。\n3. 人物属性：包括人物的职位、称号、绰号、性别、年龄、职业、性格、特长等。\n4. 主要事件：包括策略、行动、故事背景、历史事件等。\n\
      5. 事件属性：包括事件的地点、时间、事件的参与者、事件的后果等。\n6. 实体地点等名称严格使用文本中的名称，不要自己推理和创造。\n7. 根据提供的schema为每个实体分配正确的类型。\n注意：\n严格抽取triple三元组为[实体,关系,实体]，不要多余元素。\n\
      \n示例输出，包括属性、三元组及实体类型：\n{{\n    \"attributes\": {{\n      \"PERSON#1\": [\"绰号: 智多星\"\
      , \"职位: 智囊团\", \"特长: 策划\"]\n    }},\n    \"triples\": [\n      [\"PERSON#1\"\
      , \"策划\", \"智取生辰纲\"],\n      [\"智取生辰纲\", \"发生地\", \"LOCATION#1\"]\n    ],\n    \"entity_types\": {{\n      \"PERSON#1\": \"person\",\n      \"智取生辰纲\": \"event\",\n      \"LOCATION#1\": \"location\"\n    }}\n}}\n"
    novel_eng: "You are an expert information extractor and structured data organizer.\
      \ Your task is to analyze the provided text and extract as many valuable entities,\
      \ their attributes, and relations as possible in a structured JSON format. \
      \ \n\nGuidelines:\n1. Prioritize the following predefined schema for extraction;\n\
      \   ```{schema}```\n2. Flexibility: If the context doesn't fit the predefined\
      \ schema, extract the valuable knowledge as needed;\n3. Conciseness: The Attributes\
      \ and Triples you extract should be complementary and no semantic redundancy.\n\
      4. Do NOT miss any useful information in the context;\n5. Output Format: Return\
      \ only JSON as **Example Output** with:  \n   - Attributes: Map each entity\
      \ to its descriptive features.  \n   - Triples: List relations between entities\
      \ in `[entity_mention1, relation, entity_mention2]` format.\n   - Entity_types:\
      \ Map each entity to its schema type based on the provided schema.\n\nChunk:\n\
      ```{chunk}```\n\nExample Output:  \n{{\n  \"attributes\": {{\n    \"PERSON#1\"\
      : [\"profession: writer\"]\n  }},\n  \"triples\": [\n    [\"PERSON#1\", \"\
      located at\", \"LOCATION#1\"],\n    [\"PERSON#1\", \"good at\", \"playing piano\"\
      ]\n  ],\n  \"entity_types\": {{\n    \"PERSON#1\": \"person\",\n    \"LOCATION#1\"\
      : \"location\"\n  }}\n}}\n"
  decomposition:
    general: "You are a professional question decomposition expert specializing in\
      \ multi-hop reasoning.\nGiven the following ontology and the question, decompose\
      \ the complex question into 2-3 focused sub-questions and identify involved schema types.\n\nCRITICAL REQUIREMENTS:\n\
      1. Each sub-question must be:\n   - Specific and focused on a single fact or\
      \ relationship by identifing all entities, relationships, and reasoning steps\
      \ needed\n   - Answerable independently with the given ontology\n   - Explicitly\
      \ reference entities and relations from the original question\n   - Designed\
      \ to retrieve relevant knowledge for the final answer\n\n2. For simple questions\
      \ (1-2 hop), return the original question as a single sub-question\n3. Analyze the question and identify all schema types that might be involved\n4. Return\
      \ a JSON object with sub_questions array and involved_types object.\n\nOntology:\n{ontology}\n\n\
      Question: {question}\n\nExample for complex question:\nOriginal: \"Which film\
      \ has the director died earlier, Ethnic Notions or Gordon Of Ghost City?\"\n\
      Output:\n{{\n  \"sub_questions\": [\n    {{\"sub-question\": \"Who is the director of Ethnic Notions?\"\
      }},\n    {{\"sub-question\": \"Who is the director of Gordon Of Ghost City?\"\
      }},\n    {{\"sub-question\": \"When did the director of Ethnic Notions die?\"\
      }},\n    {{\"sub-question\": \"When did the director of Gordon Of Ghost City\
      \ die?\"}}\n  ],\n  \"involved_types\": {{\n    \"nodes\": [\"creative_work\", \"person\"],\n    \"relations\": [\"directed_by\"],\n    \"attributes\": [\"name\", \"date\"]\n  }}\n}}\n\nExample for simple question:\nOriginal: \"What is the capital\
      \ of France?\"\nOutput:\n{{\n  \"sub_questions\": [\n    {{\"sub-question\": \"What is the capital\
      \ of France?\"}}\n  ],\n  \"involved_types\": {{\n    \"nodes\": [\"location\"],\n    \"relations\": [\"located_in\"],\n    \"attributes\": [\"name\"]\n  }}\n}}\n"
    novel: "你是一个专业的问题分解大师，请根据以下问题和图本体模式，将问题分解为2-3个子问题，并识别涉及的schema类型。\n   要求：\n   1. 每个子问题必须：\n \
      \     - 明确且专注于一个事实或关系，通过识别所有实体、关系和推理步骤\n      - 明确引用原始问题中的实体和关系\n      - 设计为检索最终答案所需的相关知识\n\
      \   2. 对于简单问题（1-2跳），返回原始问题作为单个子问题\n   3. 分析问题并识别所有可能涉及的schema类型\n   4. 返回一个JSON对象，包含sub_questions数组和involved_types对象。\n   \n   问题：{question}\n\
      \   \n   图本体模式：{ontology}\n   \n   示例：\n   原始问题：\\\"智取生辰纲事件中，PERSON#1的策略为什么能够成功\\\"\n\
      \   输出：\n   {{\n       \\\"sub_questions\\\": [\n           {{\\\"sub-question\\\": \\\"智取生辰纲中PERSON#1的策略是什么？\\\"}},\n  \
      \           {{\\\"sub-question\\\": \\\"智取生辰纲中的PERSON、LOCATION有什么特殊属性？\\\"}}\n       ],\n       \\\"involved_types\\\": {{\n           \\\"nodes\\\": [\\\"person\\\", \\\"event\\\", \\\"location\\\"],\n           \\\"relations\\\": [\\\"策划\\\", \\\"发生地\\\"],\n           \\\"attributes\\\": [\\\"绰号\\\", \\\"职位\\\", \\\"特长\\\"]\n       }}\n   }}\n   如果是简单问题，返回原始问题作为单个子问题。\n\
      \   原始问题：\\\"智取生辰纲事件中，PERSON#1是谁\\\"\n   输出：\n   {{\n       \\\"sub_questions\\\": [\n           {{\\\"sub-question\\\": \\\"\
      智取生辰纲事件中，PERSON#1是谁？\\\"}}\n       ],\n       \\\"involved_types\\\": {{\n           \\\"nodes\\\": [\\\"person\\\", \\\"event\\\"],\n           \\\"relations\\\": [\\\"参与\\\"],\n           \\\"attributes\\\": [\\\"name\\\"]\n       }}\n   }}\n"
  retrieval:
    general: '
      你是知识问答助手，你的任务是根据提供的知识上下文回答问题。
        
        1. 仅使用提供的知识上下文中的信息来回答问题
        2. 如果知识不足，请说明无法回答
        3. 回答应精确简洁
        4. 对于事实性问题，提供具体的事实或实体名称
        5. 对于时间性问题，提供具体的日期、年份或时间段
        
        问题：{question}
        
        知识上下文：
        {context}
        
        答案（精确直接）：
    '
    general_eng: 'You are an expert knowledge assistant. Your task is to answer the question
      based on the provided knowledge context.


      1. Use ONLY the information from the provided knowledge context and try your
      best to answer the question.

      2. If the knowledge is insufficient, reject to answer the question.

      3. Be precise and concise in your answer

      4. For factual questions, provide the specific fact or entity name

      5. For temporal questions, provide the specific date, year, or time period


      Question: {question}


      Knowledge Context:

      {context}


      Answer (be specific and direct):

      '
    ircot: '你是使用迭代检索和链式思维推理的知识助手。
      
      当前问题: {current_query}
      
      可用知识上下文:
      {context}
      
      之前的思考: {previous_thoughts}
      
      步骤 {step}: 请逐步思考需要什么额外信息来完整准确地回答问题。
      
      指导原则:
      1. 分析当前知识上下文和问题
      2. 思考哪些信息可能缺失或不清楚
      3. 如果已有足够信息回答，在响应末尾写上"所以答案是:"后跟最终答案
      4. 如果需要更多信息，在响应末尾写上以"新查询是:"开头的具体查询来检索更多相关信息
      5. 推理要具体且专注
      
      你的推理:
    '
    ircot_eng: 'You are an expert knowledge assistant using iterative retrieval with chain-of-thought
      reasoning.


      Current Question: {current_query}


      Available Knowledge Context:

      {context}


      Previous Thoughts: {previous_thoughts}


      Step {step}: Please think step by step about what additional information you
      need to answer the question completely and accurately.


      Instructions:

      1. Analyze the current knowledge context and the question

      2. Think about what information might be missing or unclear

      3. If you have enough information to answer, in the end of your response, write
      "So the answer is:" followed by your final answer

      4. If you need more information, in the end of your response, write a specific
      query begin with "The new query is:" to retrieve additional relevant information

      5. Be specific and focused in your reasoning


      Your reasoning:

      '
    novel: '你是小说知识助手，你的任务是根据提供的小说知识库回答问题。

      1. 如果知识库中的信息不足以回答问题，请根据你的推理和知识回答。

      2. 回答要简洁明了。

      3. 对于事实性问题，提供具体的事实或人物名称。

      4. 对于时间性问题，提供具体的时间、年份或时间段。

      问题：{question}

      相关知识：{context}

      答案（简洁明了）：

      '
    novel_eng: "You are a novel knowledge assistant. Your task is to answer the question\
      \ based on the provided novel knowledge context.\n1. If the knowledge is insufficient,\
      \ answer the question based on your own knowledge.\n2. Be precise and concise\
      \ in your answer.\n3. For factual questions, provide the specific fact or entity\
      \ name\n4. For temporal questions, provide the specific date, year, or time\
      \ period\n\nQuestion: {question}\n\nKnowledge Context:\n{context}   \n\nAnswer\
      \ (be specific and direct):\n"
retrieval:
  agent:
    enable_ircot: true
    enable_parallel_subquestions: true
    max_steps: 5
  cache_dir: retriever/faiss_cache_new
  enable_caching: true
  enable_high_recall: true
  enable_query_enhancement: true
  enable_reranking: true
  faiss:
    device: cuda:4
    max_workers: 4
    search_k: 50
  recall_paths: 2
  similarity_threshold: 0.3
  top_k: 20
  top_k_filter: 20
triggers:
  constructor_trigger: true
  mode: agent
  retrieve_trigger: true
